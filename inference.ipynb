{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence to Sequence ChatBot Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference on seq2seq chatbot, Using CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from jieba import cut\n",
    "from p3self.lprint import lprint\n",
    "from multiprocessing import Pool\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "BS = 256# Batch size\n",
    "\n",
    "VOCAB_SEQ_IN = 3000\n",
    "VOCAB_SEQ_OUT = 3000\n",
    "\n",
    "SOS_TOKEN = 0\n",
    "EOS_TOKEN = 1\n",
    "\n",
    "LR = 5e-3\n",
    "HIDDEN_SIZE = 256\n",
    "MAX_LEN = 20\n",
    "\n",
    "VERSION = \"0.0.1\"\n",
    "\n",
    "CUDA = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class s2s_data(Dataset):\n",
    "    def __init__(self,load_io, vocab_in, vocab_out, seq_addr, build_seq=False,\n",
    "                 build_vocab = False,):\n",
    "        \"\"\"\n",
    "        vocab_in,vocab_out are csv file addresses\n",
    "        \"\"\"\n",
    "        self.load_io=load_io\n",
    "        self.vocab_in = vocab_in\n",
    "        self.vocab_out = vocab_out\n",
    "        self.seq_addr = seq_addr\n",
    "        \n",
    "        print(\"[Loading the sequence data]\")\n",
    "        \n",
    "        if build_seq:\n",
    "            self.i,self.o = self.load_io()\n",
    "            np.save(self.seq_addr,[self.i,self.o])\n",
    "        else:\n",
    "            [self.i,self.o] = np.load(self.seq_addr).tolist()\n",
    "        print(\"[Sequence data loaded]\")\n",
    "            \n",
    "        assert len(self.i)==len(self.o),\"input seq length mush match output seq length\"\n",
    "        \n",
    "        self.N = len(self.i)\n",
    "        print(\"Length of sequence:\\t\",self.N)\n",
    "        \n",
    "        if build_vocab:\n",
    "            self.vocab_i = self.build_vocab(self.i)\n",
    "            self.vocab_o = self.build_vocab(self.o)\n",
    "            \n",
    "            self.vocab_i.to_csv(self.vocab_in)\n",
    "            self.vocab_o.to_csv(self.vocab_out)\n",
    "            \n",
    "            self.print_vocab_info()\n",
    "        else:\n",
    "            self.vocab_i = pd.read_csv(self.vocab_in).fillna(\"\")\n",
    "            self.vocab_o = pd.read_csv(self.vocab_out).fillna(\"\")\n",
    "                  \n",
    "            self.print_vocab_info()\n",
    "        \n",
    "        print(\"building mapping dicts\")\n",
    "        self.i_char2idx,self.i_idx2char = self.get_mapping(self.vocab_i)\n",
    "        self.o_char2idx,self.o_idx2char = self.get_mapping(self.vocab_o)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.N\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return self.seq2idx(self.i[idx],self.i_char2idx),self.seq2idx(self.o[idx],self.o_char2idx)\n",
    "    \n",
    "    def get_full_token(self,list_of_tokens):\n",
    "        \"\"\"\n",
    "        From a list of list of tokens, to a long list of tokens, duplicate tokens included\n",
    "        \"\"\"\n",
    "        return (\" \".join(list_of_tokens)).split(\" \")\n",
    "    \n",
    "    def get_mapping(self,vocab_df):\n",
    "        char2idx=dict(zip(vocab_df[\"token\"],vocab_df[\"idx\"]))\n",
    "        idx2char=dict(zip(vocab_df[\"idx\"],vocab_df[\"token\"]))\n",
    "        return char2idx,idx2char\n",
    "    \n",
    "    def seq2idx(self,x,mapdict):\n",
    "        return np.vectorize(lambda i:mapdict[i])(x.split(\" \")).tolist()\n",
    "    \n",
    "    def get_token_count_dict(self,full_token):\n",
    "        \"\"\"count the token to a list\"\"\"\n",
    "        return Counter(full_token)\n",
    "    \n",
    "    def build_vocab(self,seq_list):\n",
    "        ct_dict = self.get_token_count_dict(self.get_full_token(seq_list))\n",
    "        ct_dict[\"SOS_TOKEN\"] = 9e9\n",
    "        ct_dict[\"EOS_TOKEN\"] = 8e9\n",
    "        tk,ct = list(ct_dict.keys()),list(ct_dict.values())\n",
    "        \n",
    "        token_df=pd.DataFrame({\"token\":tk,\"count\":ct}).sort_values(by=\"count\",ascending=False)\n",
    "        return token_df.reset_index().drop(\"index\",axis=1).reset_index().rename(columns={\"index\":\"idx\"}).fillna(\"\")\n",
    "    \n",
    "    def print_vocab_info(self):\n",
    "        self.vocab_size_i = len(self.vocab_i)\n",
    "        self.vocab_size_o = len(self.vocab_o)\n",
    "        \n",
    "        print(\"[in seq vocab address]: %s,\\t%s total lines\"%(self.vocab_in,self.vocab_size_i))\n",
    "        print(\"[out seq vocab address]: %s,\\t%s total lines\"%(self.vocab_out,self.vocab_size_o))\n",
    "            \n",
    "        print(\"Input sequence vocab samples:\")\n",
    "        print(self.vocab_i.sample(5))\n",
    "        print(\"Output sequence vocab samples:\")\n",
    "        print(self.vocab_o.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_empty():\n",
    "    return list(range(5)),list(range(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class inf_s2s(s2s_data):\n",
    "    def __init__(self,vocab_in, vocab_out):\n",
    "        super(inf_s2s,self).__init__(load_empty, vocab_in, vocab_out, seq_addr=\"/data/chat/empty.npy\", build_seq=True,\n",
    "                 build_vocab = False,)\n",
    "        \n",
    "    def feed_encoder(self,x):\n",
    "        arr = np.array(self.seq2idx(\" \".join(list(str(x))),self.i_char2idx))\n",
    "        return torch.LongTensor(arr).unsqueeze(0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Loading the sequence data]\n",
      "[Sequence data loaded]\n",
      "Length of sequence:\t 5\n",
      "[in seq vocab address]: /data/dict/chat_vocab_char_in.csv,\t5747 total lines\n",
      "[out seq vocab address]: /data/dict/chat_vocab_char_out.csv,\t5634 total lines\n",
      "Input sequence vocab samples:\n",
      "      Unnamed: 0   idx  count token\n",
      "955          955   955  278.0     短\n",
      "5473        5473  5473    1.0     鑼\n",
      "5175        5175  5175    1.0     淸\n",
      "2480        2480  2480   26.0     い\n",
      "1153        1153  1153  200.0     嗨\n",
      "Output sequence vocab samples:\n",
      "      Unnamed: 0   idx   count token\n",
      "340          340   340  2099.0     害\n",
      "3987        3987  3987     6.0     淄\n",
      "4682        4682  4682     2.0     囔\n",
      "3409        3409  3409    13.0     棠\n",
      "5180        5180  5180     1.0     檢\n",
      "building mapping dicts\n"
     ]
    }
   ],
   "source": [
    "inf=inf_s2s(vocab_in = \"/data/dict/chat_vocab_char_in.csv\",\n",
    "         vocab_out = \"/data/dict/chat_vocab_char_out.csv\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 104,  214,  610,  154,  192,    2]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf.feed_encoder(\"很高兴认识你\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True, num_layers=n_layers)\n",
    "        \n",
    "    def forward(self, input_, hidden):\n",
    "        output, hidden = self.gru(self.embedding(input_), hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    # TODO: other inits\n",
    "    def initHidden(self, batch_size):\n",
    "        en_hidden = torch.zeros(1, batch_size, self.hidden_size)\n",
    "        if CUDA:\n",
    "            en_hidden = en_hidden.cuda()\n",
    "        return en_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, n_layers=1):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True, num_layers=n_layers)\n",
    "        # TODO use transpose of embedding\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.sm = nn.LogSoftmax(dim=-1)\n",
    "        \n",
    "    def forward(self, input_, hidden):\n",
    "        emb = self.embedding(input_).unsqueeze(1)\n",
    "        # NB: Removed relu\n",
    "        res, hidden = self.gru(emb, hidden)\n",
    "        output = self.sm(self.out(res[:,0]))\n",
    "        return output, hidden\n",
    "    \n",
    "    def initInput(self,batch_size):\n",
    "        decoder_input = torch.LongTensor([SOS_TOKEN]*batch_size)\n",
    "        if CUDA:\n",
    "            decoder_input = decoder_input.cuda()\n",
    "        return decoder_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = EncoderRNN(inf.vocab_size_i,HIDDEN_SIZE)\n",
    "decoder = DecoderRNN(HIDDEN_SIZE,inf.vocab_size_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def load_s2s(version):\n",
    "    encoder.load_state_dict(torch.load(\"/data/weights/enc_%s.pkl\"%(version)))\n",
    "    decoder.load_state_dict(torch.load(\"/data/weights/dec_%s.pkl\"%(version)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_s2s(VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer(question):\n",
    "    encoder_hidden = encoder.initHidden(1)\n",
    "    decoder_input = decoder.initInput(1)\n",
    "    print(encoder_hidden.size(),decoder_input.size())\n",
    "    encoder_output,encoder_hidden = encoder(question,encoder_hidden)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "    \n",
    "    i = 0\n",
    "    output=list()\n",
    "    last_idx = 9e9\n",
    "    while (i < MAX_LEN and last_idx != EOS_TOKEN):\n",
    "        last_idx,decoder_hidden = decoder(decoder_input,decoder_hidden)\n",
    "        last_idx = torch.max(decoder_input,dim=-1)[1].item()\n",
    "        output.append(last_idx)\n",
    "        i += 1\n",
    "    print(output)\n",
    "    output_char = \"\".join(np.vectorize(lambda x:inf.o_idx2char[x])(output).tolist())\n",
    "    print(output_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 256]) torch.Size([1])\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "SOS_TOKENSOS_TOKENSOS_TOKENSOS_TOKENSOS_TOKENSOS_TOKENSOS_TOKENSOS_TOKENSOS_TOKENSOS_TOKENSOS_TOKENSOS_TOKENSOS_TOKENSOS_TOKENSOS_TOKENSOS_TOKENSOS_TOKENSOS_TOKENSOS_TOKENSOS_TOKEN\n"
     ]
    }
   ],
   "source": [
    "answer(inf.feed_encoder(\"你叫什么名字\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
